{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2. Event-data Representation and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **goals** of this exercise are:\n",
    "- to get familiarized with the data output by an event-based camera\n",
    "- to practice on converting the event data into grid-based representations, which is a common practice of many algorithms (without judging whether it is \"optimal\" or not).\n",
    "- to produce \"pretty plots\" (never underestimate the value good figures on reports and papers).\n",
    "\n",
    "Since we do not have a camera at hand to play with, we will use data from a dataset. You may find a list of [datasets here](https://github.com/uzh-rpg/event-based_vision_resources/blob/master/README.md#datasets-sorted-by-topic). In particular, we use data from the paper [Event Camera Dataset and Simulator (IJRR'17)](http://rpg.ifi.uzh.ch/davis_data.html) because event data is available in simple txt format. The sequences in this dataset were recorded with a DAVIS240C camera (by iniVation) and they also contain grayscale frames, recorded at about 25 Hz (frames per second). These can be helpful to get a better idea of the scene. We use the [slider_depth](http://rpg.ifi.uzh.ch/datasets/davis/slider_depth.zip) sequence because it is a small file. Moreover we use shortened files to process a few thousand events (out of millions of events that these files may contain). One you are familiar with the exercise, feel free to use other sequences or data from other publicly available datasets.\n",
    "\n",
    "This exercise is not as guided as the first one. Instead of filling in the blanakcs, here we show the plots that the code that you will write is supposed to produce (approximately). Your taks is to write such a code with the tools that we learned in the previous exercise (numpy, matplotlib, opencv).\n",
    "\n",
    "Try also to implement it nicely with utility functions. Try to come up with new plots to reveal the information in the event data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data format\n",
    "\n",
    "Events in the txt files of the IJRR'17 dataset are given one per line. For example, the first ten lines of the slider_depth txt file are:\n",
    "\n",
    "    0.003811000 96 133 0\n",
    "    0.003820001 127 171 0\n",
    "    0.003836000 4 160 0\n",
    "    0.003837000 149 122 0\n",
    "    0.003848001 63 121 1\n",
    "    0.003849001 17 144 1\n",
    "    0.003852000 92 119 0\n",
    "    0.003866001 16 137 1\n",
    "    0.003875000 156 71 0\n",
    "    0.003879000 26 149 0\n",
    "\n",
    "That is, data is given in the form:\n",
    "\n",
    "    t, x, y, p\n",
    "\n",
    "timestamp $t$ (in seconds), $x$ pixel coordinate (horizontal or column index), $y$ pixel coordinate (vertical coordinate or row index) and polarity $p$ (1 bit of information with the sign of the brightness change: 1 if positive, 0 if negative). Since the DAVIS240C has a spatial resolution of 240 x 180 pixels, $x$ and $y$ adopt values in $\\{0,\\ldots,239\\}$ and $\\{0,\\ldots,179\\}$, respectively.\n",
    "\n",
    "You first task is to read the data from file (loading it into temporal variables)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Space-time plot\n",
    "\n",
    "The following plots were generated with events between $N_e=5000$ and $N_e = 50000$.\n",
    "\n",
    "The following figure shows a visualization of (the first 2000) events in space-time (image plane of the camera amd time).\n",
    "\n",
    "![Events, space-time and polarity](images/space_time_pol.png)\n",
    "\n",
    "Let us first try to plot something simpler (with fewer dimensions).\n",
    "\n",
    "\n",
    "## Image-like (2D grid) representation\n",
    "\n",
    "### Histograms of events (Event count)\n",
    "Write Python code to generate the following image, which has been generated by considering the first $N_e=5000$ in the file and adding the event polarities pixel-wise.\n",
    "\n",
    "![balance_polarities_gray](images/balance_polarities_gray.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What do the \"three colors\" in the image represent?\n",
    "- What is the maximum number of positive events at any pixel?\n",
    "- and the maximum number of negative events at any pixel?\n",
    "- What could such an image be used for?\n",
    "\n",
    "\n",
    "Next, consider using [pseudocolor](https://en.wikipedia.org/wiki/False_color) to display the events. Write code to generate the following image.\n",
    "\n",
    "![balance_polarities_red_blue](images/balance_polarities_red_blue.png)\n",
    "\n",
    "- What do the white, red and blue pixel colors represent?\n",
    "- Why didn't we use green instead of blue?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to plot an image where every pixel may have only three possible values (ternary image): -1, 0, 1.\n",
    "Use for example, the last event polarity at each pixel.\n",
    "\n",
    "![ternary_gray](images/ternary_gray.png)\n",
    "\n",
    "- What could this type of representation be good for compared to the histogram one (above)?\n",
    "\n",
    "Next, split by polarity: plot two images instead of one; one image for each event polarity. That is, compute two histograms of events. One for positive events and one for negative events, as shown next. Can you clearly identify both polarities in the moving edges?\n",
    "\n",
    "![](images/hist2d_pos_veridi.png)\n",
    "![](images/hist2d_neg_veridi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images of timestamps (\"time surfaces\", \"time maps\" or \"surface of active events\")\n",
    "\n",
    "Other useful representations are those that, instead of counting events at every pixel, just show a timestamp per pixel. It could be the last timestamp, an average timestamp or a timestamp with exponential decay.\n",
    "\n",
    "Next, write code to replicate the type of time-images of the [2015 PAMI paper HOTS, Fig. 2](https://www.neuromorphic-vision.com/public/publications/1/publication.pdf).\n",
    "Use 50000 events to better see the traces of the edges as they trigger events when they move through the image plane.\n",
    "\n",
    "$ image(x,y; t) = exp(-|t-T(x,y)| / \\tau)$\n",
    "\n",
    "This is equation (3) in the above paper, with $R=0$.\n",
    "Tha paper uses $\\tau = 50$ ms (see the bottom of page 8). For the plots below, a value $\\tau = 30$ ms is used. $\\tau$ is a tunable parameter that depends on the motion in the scene.\n",
    "\n",
    "Also note that the paper uses the polarity $p$ as an argument of the time map $T$, while we do not explicitly write it. We want to plot time maps with both polarities on the same map, which is not easy to write with such a notation.\n",
    "\n",
    "![](images/ts_exp_pol.png)\n",
    "\n",
    "Next, split by polarity: plot two images instead of one; one image for each event polarity\n",
    "\n",
    "![](images/ts_exp_pos.png)\n",
    "![](images/ts_exp_neg.png)\n",
    "\n",
    "- Describe what you see in this representation and whether it is better or not to split by polarity. In what situations?\n",
    "\n",
    "<!-- ![](images/ts_exp_pol_red_blue.png) \n",
    "![](images/ts_exp_balance_pol_red_blue.png) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Average timestamp images**. Each pixel contains the average timestamp of the events that happened in it in the last few milliseconds. (There is no exponential decay, just an average).\n",
    "\n",
    "![](images/t_ave_both_pols.png)\n",
    "\n",
    "Next, split by polarity:\n",
    "\n",
    "![](images/t_ave_pos.png)\n",
    "![](images/t_ave_neg.png)\n",
    "\n",
    "- Describe what you oberve compared to previous representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Space-time plots\n",
    "\n",
    "Next, we take a look at different ways to visualize events in space-time. Such a space-time is obtained by considering a temporal window of the signal that is output by the camera as a response of the light arriving at the image plane (i.e., the \"retina\").\n",
    "\n",
    "## Point set (or point \"cloud\")\n",
    "\n",
    "Write Python code to plot the first $N_e = 2000$ events in space-time:\n",
    "\n",
    "![Events, space-time and polarity](images/space_time_pol.png)\n",
    "\n",
    "You may find the [3D scatterplot example](https://matplotlib.org/3.1.1/gallery/mplot3d/scatter3d.html) useful.\n",
    "\n",
    "Try experimenting by moving around the viewpoint (clicking on the figure generated by Python's matplotlib).\n",
    "\n",
    "- For us, humans, is the information more intelligible from any specific viewpoint?\n",
    "- What information do you gain by looking at this point cloud from directions parallel to each of the coordinate axes?\n",
    "\n",
    "Then, write a function to generate a short **[movie](movie.mp4)** that smoothly shows the intermediate viewpoints between two specified ones (the start and end viewpoints). See the following VLC player screenshot.\n",
    "Suggestion: use the matplotlib command `ax.view_init(azim=XXX,elev=ZZZ)`. Write images to disk and create a movie from them using ffmpeg. There is no need to install ffmpeg; you may use the [static build](https://johnvansickle.com/ffmpeg/). Video [coding options](https://trac.ffmpeg.org/wiki/Encode/H.264), such as lossless.\n",
    "\n",
    "![movie snapthot on VLC](images/movie_vlc_pointset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voxel grid representation\n",
    "\n",
    "Next, write code to convert the event data into a 3D histogram. We will collect the events into bins: 1 bin per pixel in space and say 5 bins in time. Feel free to write your own function to compute the 3D histogram or to use numpy's [histogramdd](https://numpy.org/doc/stable/reference/generated/numpy.histogramdd.html?highlight=histogramdd#numpy.histogramdd) function. Actually it is good to compute it using both methods to make sure that both agree.\n",
    "\n",
    "**Plain histogram**. Write python code to compute the 3D histogram and display it as a voxel grid. \n",
    "Every voxel counts the number of events falling (i.e., binned) within it.\n",
    "Suggestion: [this sample code](https://matplotlib.org/3.1.1/gallery/mplot3d/voxels_rgb.html#sphx-glr-gallery-mplot3d-voxels-rgb-py)\n",
    "\n",
    "![voxel histogram](images/voxel_nn.png)\n",
    "\n",
    "- What are the minimum and maximum number of events at any voxel?\n",
    "- How many voxels are there? how many are \"occupied\" (i.e., have a non-zero value)? (voxel grids are also known as \"occupancy maps\" in robotics). What is the ratio between these numbers? (how sparse is the data)?\n",
    "\n",
    "**Smooth histogram that also includes polarity information**.\n",
    "Next, modify the code you have written to include polarity. That is, instead of counting events on every bin, \"count\" the polarity. Moreover, to make the histogram smoother, use a linear voting scheme by which an event splits its polarity in its two closest temporal bins. The split takes into account the distance from the event to both bins. (This idea of smoothing a histogram is similar to the idea of kernel density estimation). The following plot illustrates this idea of \"smoothing\" the histogram.\n",
    "\n",
    "![histogram smoothing](images/histogram_smoothing.png)\n",
    "\n",
    "Here is the voxel grid obtained by using linear voting of polarity (per-voxel balance of linearly-interpolated polarity). Grayscale values are used: dark values represent negative events (voxels with negative balance of polarities) and bright values represent positive events (voxels with positive balance of polarities).\n",
    "\n",
    "![voxel linear voting with polarity](images/voxel_linvote_pol.png)\n",
    "\n",
    "- What are the minimum and maximum balance of event polarity at any voxel?\n",
    "- Does this way of computing the histogram, including polarity, affect the above \"sparsity ratio\"?\n",
    "- How does the (3D) voxel grid representation compare to 2D representations? For example in terms of memory, in terms of preservation of the information contained in the event data?\n",
    "- What could the voxel grid representation be good for?\n",
    "- How would you interpret the above voxel grid in terms of a continuous \"polarity field\" $p(x,y,t)$ or the temporal derivative of the brightness signal arriving at the sensor $\\frac{\\partial L}{\\partial t}(x,y,t)$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
